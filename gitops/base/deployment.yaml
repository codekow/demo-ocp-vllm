---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm
  labels:
    deployment: vllm
  annotations:
    argocd.argoproj.io/sync-wave: "1"
    image.openshift.io/triggers: >-
      [{"from":{"kind":"ImageStreamTag","name":"vllm:latest"},"fieldPath":"spec.template.spec.containers[?(@.name==\"vllm-server\")].image","paused":"true"}]
spec:
  replicas: 1
  selector:
    matchLabels:
      deployment: vllm
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        deployment: vllm
    spec:
      restartPolicy: Always
      containers:
        - name: vllm-server
          env:
            - name: HUGGING_FACE_HUB_TOKEN
              value: ''
            - name: DOWNLOAD_MODEL
              value: ''
            - name: VLLM_TARGET_DEVICE
              value: cpu
          command:
          - /bin/bash
          - -c
          - |
            echo python3 -m vllm.entrypoints.openai.api_server \
            --model \
            "${DOWNLOAD_MODEL:-TinyLlama/TinyLlama-1.1B-Chat-v1.0}" \
            --download-dir /models-cache \
            --max-model-len  "2048"
            python -m http.server 8080
          image: 'vllm:latest'
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          resources:
            limits:
              cpu: '2'
              memory: 8Gi
            requests:
              cpu: '1'
              memory: 4Gi
          # startupProbe:
          #   httpGet:
          #     path: /health
          #     port: http
          #     scheme: HTTP
          #   timeoutSeconds: 1
          #   periodSeconds: 30
          #   successThreshold: 1
          #   failureThreshold: 10
          # readinessProbe:
          #   httpGet:
          #     path: /health
          #     port: http
          #     scheme: HTTP
          #   timeoutSeconds: 5
          #   periodSeconds: 30
          #   successThreshold: 1
          #   failureThreshold: 3
          # livenessProbe:
          #   httpGet:
          #     path: /health
          #     port: http
          #     scheme: HTTP
          #   timeoutSeconds: 8
          #   periodSeconds: 100
          #   successThreshold: 1
          #   failureThreshold: 3
          volumeMounts:
            - name: models-cache
              mountPath: /models-cache
            - name: shm
              mountPath: /dev/shm
      volumes:
        - name: models-cache
          persistentVolumeClaim:
            claimName: vllm-cache
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 1Gi
